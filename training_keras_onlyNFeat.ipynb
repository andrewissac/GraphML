{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dgl\n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from trainresults import TrainResults\n",
    "from train_eval_func import train, evaluate\n",
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from TauGraphDatasetInfo import TauGraphDatasetInfo\n",
    "from TauGraphDataset import TauGraphDataset, GetNodeFeatureVectors, GetEdgeFeatureVectors\n",
    "from TauGraphDataset import GetNeighborNodes, GetEdgeList, GetEdgeFeatureVectorsFromSourceNode, Graph2FlatZeropaddedList\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetNames(datasetDir):\n",
    "    files = glob.glob(datasetDir + '/*.json', recursive=True)\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n",
      "['Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n"
     ]
    }
   ],
   "source": [
    "datasetDir = '/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets'\n",
    "datasetDirs, datasetNames = getDatasetNames(datasetDir)\n",
    "print(datasetDirs)\n",
    "print(datasetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "<TauGraphDataset.TauGraphDataset object at 0x7f816024c0f0>\n"
     ]
    }
   ],
   "source": [
    "dataset = TauGraphDataset(datasetNames[0], datasetDirs[0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Graphs_DYJetsToLL_M-50_genuineTaus_and_jets,\n",
      " directory: /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "label: 1\n",
      "graph classes: ['0', '1']\n",
      "dataset graph count: 200000\n",
      "nodeFeatKeys: ['pt', 'eta', 'phi', 'mass', 'charge', 'particleType', 'summand']\n",
      "edgeFeatKeys: ['deltaEta', 'deltaPhi', 'deltaR']\n",
      "graphFeatkeys: ['nodeCount', 'tau_byDeepTau2017v2p1VSjet']\n",
      "max node count: 81\n",
      "min node count: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'name: {datasetNames[0]},\\n directory: {datasetDirs[0]}')\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'label: {label}')\n",
    "print(f'graph classes: {dataset.graphClasses}')\n",
    "print(f'dataset graph count: {dataset.num_graphs}')\n",
    "print(f'nodeFeatKeys: {dataset.nodeFeatKeys}')\n",
    "print(f'edgeFeatKeys: {dataset.edgeFeatKeys}')\n",
    "print(f'graphFeatkeys: {dataset.graphFeatKeys}')\n",
    "print(f'max node count: {dataset.maxNodeCount}')\n",
    "print(f'min node count: {dataset.minNodeCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "nFeatDim: 7\n",
      "eFeatDim: 3\n",
      "maxNodeCount: 81\n",
      "\n",
      "node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\n",
      " nFeatDim + eFeatDim * (maxNodeCount-1) = 7 + 3 * 80 =  247\n",
      "The (maxNodeCount-1) comes from fully connected graphs without self-loops\n",
      "\n",
      "only node features dim per Node: nFeatDim=7\n",
      "\n",
      "node + edge features with zero padding to fill until maxNodeCount leads to inputsize: 20007\n",
      "check example: node + edge features list size: 20007\n",
      "\n",
      "only node features with zero padding to fill until maxNodeCount leads to inputsize: 567\n",
      "check example: only node features list size: 567\n"
     ]
    }
   ],
   "source": [
    "graphs, labels = dataset[:]\n",
    "g = graphs[0]\n",
    "nFeatDim = dataset.dim_nfeats\n",
    "eFeatDim = dataset.dim_efeats\n",
    "maxNodeCount = dataset.maxNodeCount\n",
    "print(g)\n",
    "print(f'nFeatDim: {nFeatDim}')\n",
    "print(f'eFeatDim: {eFeatDim}')\n",
    "print(f'maxNodeCount: {maxNodeCount}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDim = nFeatDim + eFeatDim * (maxNodeCount - 1)\n",
    "print(f'node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\\n',\n",
    "      f'nFeatDim + eFeatDim * (maxNodeCount-1) = {nFeatDim} + {eFeatDim} * {maxNodeCount - 1} = ',\n",
    "      f'{nodeAndEdgeFeaturePaddedDim}')\n",
    "print(f'The (maxNodeCount-1) comes from fully connected graphs without self-loops')\n",
    "print()\n",
    "print(f'only node features dim per Node: nFeatDim={nFeatDim}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDimInputSize = nodeAndEdgeFeaturePaddedDim * maxNodeCount\n",
    "nodeFeaturePaddedDimInputSize = nFeatDim * maxNodeCount\n",
    "print(f'node + edge features with zero padding to fill until maxNodeCount leads to inputsize: {nodeAndEdgeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = True\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: node + edge features list size: {len(temp)}')\n",
    "print()\n",
    "print(f'only node features with zero padding to fill until maxNodeCount leads to inputsize: {nodeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = False\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: only node features list size: {len(temp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputData(dgldataset, useEdgeFeatures):\n",
    "    inputs = [] \n",
    "    graphs, labels = dgldataset[:]\n",
    "    maxNodeCount = dgldataset.maxNodeCount\n",
    "    nFeatDim = dgldataset.dim_nfeats\n",
    "    eFeatDim = dgldataset.dim_efeats\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    it = 0\n",
    "    \n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        inputs.append(Graph2FlatZeropaddedList(graphs[i], nFeatDim, eFeatDim, maxNodeCount, useEdgeFeatures))\n",
    "\n",
    "    # Stack all inputs_ vertically\n",
    "    print(type(inputs))\n",
    "    inputs = np.array(inputs, dtype=np.float32)\n",
    "    print(inputs)\n",
    "    print(type(inputs))\n",
    "    inputs = np.vstack(inputs)\n",
    "    print(inputs)\n",
    "    \n",
    "\n",
    "    # Stack all labels_ horizontally\n",
    "    labels = np.hstack(labels)\n",
    "\n",
    "    print(\"Input shape: \", inputs.shape)\n",
    "    print(\"Labels shape: \", labels.shape)\n",
    "\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    print(labels.shape)\n",
    "    print(labels[0])\n",
    "    end = time.time() - start\n",
    "    print(f'graphs to flattened zero padded list took {end:.2f} seconds ({end/60:.2f} minutes)')\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:37<00:00, 2045.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "Input shape:  (200000, 567)\n",
      "Labels shape:  (200000,)\n",
      "(200000, 2)\n",
      "[0. 1.]\n",
      "graphs to flattened zero padded list took 101.27 seconds (1.69 minutes)\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = getInputData(dataset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenerator(inputs, labels, batchsize):\n",
    "    while True:\n",
    "        start = 0\n",
    "        end = batchsize\n",
    "\n",
    "        while start  < len(inputs): \n",
    "            # load your images from numpy arrays or read from directory\n",
    "            x = inputs[start:end] \n",
    "            y = labels[start:end]\n",
    "            yield x, y\n",
    "\n",
    "            start += batchsize\n",
    "            end += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"KerasModel_NodeFeatOnly\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 16)                9088      \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 9,394\n",
      "Trainable params: 9,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"KerasModel_NodeFeatOnly\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 16)                9088      \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 9,394\n",
      "Trainable params: 9,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "outputFolder = path.join(datasetDir, 'Output_Keras_NodeFeatOnly')\n",
    "Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = keras.Sequential(name=\"KerasModel_NodeFeatOnly\")\n",
    "inputDim = nFeatDim * maxNodeCount\n",
    "model.add(keras.layers.InputLayer(input_shape=(inputDim,), name=\"input\"))\n",
    "model.add(keras.layers.Dense(16, activation='relu', name=\"dense1\"))\n",
    "model.add(keras.layers.Dense(16, activation='relu', name=\"dense2\"))\n",
    "model.add(keras.layers.Dense(2, activation='softmax', name=\"output\"))\n",
    "model.summary()\n",
    "\n",
    "lossfunction = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path.join(outputFolder,'keras_nodeFeatOnly_bestmodel.h5'), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "csvlogger = tf.keras.callbacks.CSVLogger(filename=path.join(outputFolder, 'results_keras_nodeFeatOnly_bestmodel.csv'), separator=',', append=False)\n",
    "callbacks = [modelcheckpoint, csvlogger]\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss=lossfunction, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 140000\n",
      "validation samples: 40200\n",
      "test samples: 19800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_testAndVal, y_train, y_testAndVal = train_test_split(inputs, labels, test_size=0.3, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testAndVal, y_testAndVal, test_size=0.33, shuffle=False)\n",
    "print(f'train samples: {len(X_train)}')\n",
    "print(f'validation samples: {len(X_val)}')\n",
    "print(f'test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "136/136 [==============================] - 3s 12ms/step - loss: 0.4030 - accuracy: 0.8168 - val_loss: 0.2719 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27195, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2632 - accuracy: 0.8969 - val_loss: 0.2626 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27195 to 0.26257, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2574 - accuracy: 0.8980 - val_loss: 0.2588 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26257 to 0.25881, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2543 - accuracy: 0.8992 - val_loss: 0.2562 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25881 to 0.25617, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2515 - accuracy: 0.9002 - val_loss: 0.2539 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25617 to 0.25385, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2494 - accuracy: 0.9010 - val_loss: 0.2518 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25385 to 0.25177, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2473 - accuracy: 0.9021 - val_loss: 0.2499 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25177 to 0.24987, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.2455 - accuracy: 0.9026 - val_loss: 0.2484 - val_accuracy: 0.9020\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.24987 to 0.24839, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2439 - accuracy: 0.9032 - val_loss: 0.2472 - val_accuracy: 0.9031\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24839 to 0.24724, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2421 - accuracy: 0.9040 - val_loss: 0.2460 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24724 to 0.24599, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2402 - accuracy: 0.9051 - val_loss: 0.2445 - val_accuracy: 0.9038\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.24599 to 0.24446, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2388 - accuracy: 0.9054 - val_loss: 0.2433 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24446 to 0.24327, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9058 - val_loss: 0.2427 - val_accuracy: 0.9044\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.24327 to 0.24266, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2366 - accuracy: 0.9061 - val_loss: 0.2420 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24266 to 0.24203, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2355 - accuracy: 0.9066 - val_loss: 0.2416 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24203 to 0.24161, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2347 - accuracy: 0.9070 - val_loss: 0.2411 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.24161 to 0.24114, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2341 - accuracy: 0.9073 - val_loss: 0.2406 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24114 to 0.24061, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9076 - val_loss: 0.2403 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24061 to 0.24029, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.2327 - accuracy: 0.9077 - val_loss: 0.2396 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24029 to 0.23958, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.2321 - accuracy: 0.9081 - val_loss: 0.2392 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23958 to 0.23918, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2318 - accuracy: 0.9080 - val_loss: 0.2388 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23918 to 0.23883, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2313 - accuracy: 0.9083 - val_loss: 0.2387 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.23883 to 0.23867, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2306 - accuracy: 0.9084 - val_loss: 0.2385 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23867 to 0.23850, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2300 - accuracy: 0.9087 - val_loss: 0.2383 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.23850 to 0.23825, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2298 - accuracy: 0.9087 - val_loss: 0.2381 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.23825 to 0.23806, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.2293 - accuracy: 0.9088 - val_loss: 0.2374 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23806 to 0.23745, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.2288 - accuracy: 0.9091 - val_loss: 0.2364 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23745 to 0.23640, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.2286 - accuracy: 0.9091 - val_loss: 0.2357 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23640 to 0.23569, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.2280 - accuracy: 0.9093 - val_loss: 0.2352 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.23569 to 0.23525, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.2275 - accuracy: 0.9096 - val_loss: 0.2348 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.23525 to 0.23481, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeFeatOnly/keras_nodeFeatOnly_bestmodel.h5\n"
     ]
    }
   ],
   "source": [
    "batchsize=1024\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    x = datagenerator(X_train, y_train, batchsize=batchsize),\n",
    "    validation_data = datagenerator(X_val, y_val,batchsize=batchsize),\n",
    "    steps_per_epoch = len(X_train)//batchsize,\n",
    "    validation_steps = len(X_val)//batchsize,\n",
    "    shuffle=False, # at creation from rootfiles -> graphs already shuffled dataset\n",
    "    epochs = 30, # doesnt matter, since we use early stopping\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "end = time.time() - start\n",
    "print(f'training took {end:.2f} seconds ({end/60:.2f} minutes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputFolder = path.join(datasetDir, 'Output_Keras_NodeFeatOnly')\n",
    "\n",
    "#model = keras.models.load_model(path.join(outputFolder, 'keras_nodeFeatOnly_bestmodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'loss': [0.4029580056667328, 0.26321274042129517, 0.25740376114845276, 0.254263311624527, 0.2515096664428711, 0.2493506371974945, 0.24726329743862152, 0.2454703003168106, 0.24394653737545013, 0.24208103120326996, 0.24017147719860077, 0.23883184790611267, 0.237776979804039, 0.23663264513015747, 0.2354976385831833, 0.23467540740966797, 0.2340826392173767, 0.23337422311306, 0.23274736106395721, 0.23206248879432678, 0.2318488508462906, 0.2313382923603058, 0.23057131469249725, 0.2300124615430832, 0.22976182401180267, 0.22929516434669495, 0.22881312668323517, 0.22859112918376923, 0.22803953289985657, 0.22754377126693726], 'accuracy': [0.8167580962181091, 0.896917462348938, 0.8980111479759216, 0.8992199897766113, 0.900177001953125, 0.9010188579559326, 0.9020910263061523, 0.9025803208351135, 0.9032207131385803, 0.9040337800979614, 0.9050555229187012, 0.9053577780723572, 0.9058254957199097, 0.9061492681503296, 0.9066385626792908, 0.906998336315155, 0.9073293209075928, 0.9076027274131775, 0.9077466726303101, 0.9081423878669739, 0.9080272912979126, 0.9082575440406799, 0.9084086418151855, 0.9087180495262146, 0.9086604714393616, 0.908761203289032, 0.909063458442688, 0.909063458442688, 0.9093080759048462, 0.9095599055290222], 'val_loss': [0.2719466984272003, 0.2625688910484314, 0.25880691409111023, 0.2561655044555664, 0.2538507580757141, 0.25176918506622314, 0.24987152218818665, 0.2483864575624466, 0.24724197387695312, 0.24599452316761017, 0.2444637268781662, 0.2432650774717331, 0.2426632195711136, 0.24203146994113922, 0.24160683155059814, 0.24113750457763672, 0.24060863256454468, 0.24028781056404114, 0.2395777404308319, 0.23918350040912628, 0.23882882297039032, 0.23867113888263702, 0.23850314319133759, 0.23825271427631378, 0.2380550354719162, 0.23744754493236542, 0.236400306224823, 0.23569241166114807, 0.23524822294712067, 0.23481141030788422], 'val_accuracy': [0.89453125, 0.8973106741905212, 0.8986127972602844, 0.8990384340286255, 0.9001902937889099, 0.9007161259651184, 0.9013922214508057, 0.9020182490348816, 0.9030699133872986, 0.9033453464508057, 0.9037960767745972, 0.9041716456413269, 0.9044221043586731, 0.9042468070983887, 0.9046474099159241, 0.9049229025840759, 0.9047726392745972, 0.9048477411270142, 0.9053735733032227, 0.9058743715286255, 0.9059244990348816, 0.9065755009651184, 0.9060496687889099, 0.90625, 0.906325101852417, 0.906174898147583, 0.9063501358032227, 0.907151460647583, 0.9074018597602844, 0.9073266983032227]}\n",
      "4375/4375 [==============================] - 18s 4ms/step - loss: 0.2252 - accuracy: 0.9107\n",
      "619/619 [==============================] - 3s 4ms/step - loss: 0.2312 - accuracy: 0.9128\n",
      "1257/1257 [==============================] - 5s 4ms/step - loss: 0.2348 - accuracy: 0.9075\n",
      "Train: 0.911, Valid: 0.907, Test: 0.913, AUC: 0.965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN output plot\n",
    "predictions = model.predict(X_test)\n",
    "#print(predictions)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "\n",
    "def createFigure():\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    ax.tick_params(pad=7)\n",
    "    return fig, ax\n",
    "\n",
    "# TODO: check which order is actually signal (genuineTau) and which are background (fakeTau)\n",
    "genuineTau_decisions = predictions[:,0]\n",
    "fakeTau_decisions = predictions[:,1]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.hist(genuineTau_decisions, label='Genuine Taus', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, # normalize to form a probability density\n",
    "        linewidth=lw)\n",
    "plt.hist(fakeTau_decisions, label='Jets', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, linewidth=lw) # normalize to form a probability density\n",
    "plt.xlabel('Neural Network output') # add x-axis label\n",
    "plt.ylabel('Arbitrary units') # add y-axis label\n",
    "plt.legend(loc=\"upper center\") # add legend\n",
    "plt.savefig(path.join(outputFolder, \"NN_output.png\"))\n",
    "plt.clf()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test.argmax(axis=1), predictions[:, 1])\n",
    "roc_auc = auc(fpr, tpr) # area under curve (AUC), ROC = Receiver operating characteristic\n",
    "\n",
    "fig, ax = createFigure()\n",
    "ax.plot(fpr, tpr, label=f'ROC (area = {roc_auc:.2f})', linewidth=lw)\n",
    "ax.plot([0, 1], [0, 1], '--', color='red', label='Luck', linewidth=lw)\n",
    "ax.set_xlabel('False Positive Rate') \n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "outputFilePath = path.join(outputFolder, 'ROC.png')\n",
    "plt.savefig(outputFilePath)\n",
    "plt.clf()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(history.history)\n",
    "\n",
    "# Plot accuracy of NN\n",
    "fig, ax = createFigure()\n",
    "ax.plot(history.history['accuracy'], label='Training', linewidth=lw)\n",
    "ax.plot(history.history['val_accuracy'], label='Validation', linewidth=lw)\n",
    "ax.set_ylabel('Accuracy', labelpad=xLabelPad, fontsize=xyLabelFontSize)\n",
    "ax.set_xlabel('Epoch', labelpad=yLabelPad, fontsize=xyLabelFontSize)\n",
    "ax.legend()\n",
    "outputFilePath = path.join(outputFolder, 'accuracy.png')\n",
    "plt.savefig(outputFilePath)\n",
    "plt.clf()\n",
    "# Plot loss of NN\n",
    "fig, ax = createFigure()\n",
    "ax.plot(history.history['loss'], label=\"Training\",linewidth=lw)\n",
    "ax.plot(history.history['val_loss'], label=\"Validation\", linewidth=lw)\n",
    "ax.set_ylabel('Loss', labelpad=xLabelPad, fontsize=xyLabelFontSize)\n",
    "ax.set_xlabel('Epoch', labelpad=yLabelPad, fontsize=xyLabelFontSize)\n",
    "ax.legend()\n",
    "outputFilePath = path.join(outputFolder, 'epochloss.png')\n",
    "plt.savefig(outputFilePath)\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "_, valid_acc = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f'Train: {train_acc:.3f}, Valid: {valid_acc:.3f}, Test: {test_acc:.3f}, AUC: {roc_auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "print(predictions.argmax(1)[:100])\n",
    "print(y_test.argmax(1)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.hist(genuineTau_decisions, label='Genuine Taus', \n",
    "        histtype='step',\n",
    "         density=True,\n",
    "        linewidth=lw)\n",
    "plt.hist(fakeTau_decisions, label='Jets', \n",
    "        histtype='step', \n",
    "         density=True,\n",
    "         linewidth=lw)\n",
    "plt.xlabel('Neural Network output') # add x-axis label\n",
    "plt.ylabel('Arbitrary units') # add y-axis label\n",
    "plt.legend(loc=\"upper center\") # add legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genuineTau_decisions[:100])\n",
    "print(fakeTau_decisions[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e711687f31016629c64c84d23d27d9292aefc640ef90f9639fb07f22fea1b3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
