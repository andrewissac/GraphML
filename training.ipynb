{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dgl\n",
    "import copy\n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import awkward as ak\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from trainresults import TrainResults\n",
    "from train_eval_func import train, evaluate\n",
    "from copy import deepcopy\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from TauGraphDatasetInfo import TauGraphDatasetInfo\n",
    "from CustomGCNs import CustomGCN_OnlyNFeatSumMsg, CustomGCN_OnlyNFeatMeanMsg\n",
    "from TauGraphDataset import TauGraphDataset, GetNodeFeatureVectors, GetEdgeFeatureVectors, GetNeighborNodes, GetEdgeList\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def trainEpochs(model, device, dataloader, optimizer, loss_fn, batchsize, nEpochs):\n",
    "    results = TrainResults()\n",
    "    results.startTrainingTimer()\n",
    "    bestModel = None\n",
    "    bestValAcc = 0.0\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        # train\n",
    "        epochLoss = train(model, device, dataloader, optimizer, loss_fn, batchsize, results)\n",
    "\n",
    "        # evaluate\n",
    "        train_result = evaluate(model, device, train_dataloader, loss_fn)\n",
    "        val_result = evaluate(model, device, val_dataloader, loss_fn)\n",
    "        test_result = evaluate(model, device, test_dataloader, loss_fn)\n",
    "\n",
    "        results.addEpochResult(epochLoss, train_result, val_result, test_result)\n",
    "        results.printLastResult()\n",
    "\n",
    "        if results.best_val_acc > bestValAcc:\n",
    "            bestValAcc = results.best_val_acc\n",
    "            bestModel = copy.deepcopy(model)\n",
    "    \n",
    "    results.endTrainingTimer()\n",
    "\n",
    "    return results, bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetNames(datasetDir):\n",
    "    files = glob.glob(datasetDir + '/*.json', recursive=True)\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "['/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n",
      "['Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "\n",
    "datasetDir = '/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets'\n",
    "datasetDirs, datasetNames = getDatasetNames(datasetDir)\n",
    "print(datasetDirs)\n",
    "print(datasetNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetName = datasetNames[0]\n",
    "datasetDir = datasetDirs[0]\n",
    "dataset = TauGraphDataset(datasetName, datasetDir)\n",
    "dataset.printProperties()\n",
    "\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'Label: {label}')\n",
    "print(GetNodeFeatureVectors(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Epoch: 0, Loss: 0.6889, Validation Loss: 0.5552, Train: 0.632, Validation: 0.631, Test: 0.632, AUC: 0.852\n",
      "Epoch: 1, Loss: 0.5119, Validation Loss: 0.4721, Train: 0.815, Validation: 0.814, Test: 0.819, AUC: 0.916\n",
      "Epoch: 2, Loss: 0.4408, Validation Loss: 0.4079, Train: 0.866, Validation: 0.866, Test: 0.871, AUC: 0.938\n",
      "Epoch: 3, Loss: 0.3799, Validation Loss: 0.3502, Train: 0.883, Validation: 0.883, Test: 0.887, AUC: 0.945\n",
      "Epoch: 4, Loss: 0.3272, Validation Loss: 0.3056, Train: 0.893, Validation: 0.891, Test: 0.896, AUC: 0.952\n",
      "Epoch: 5, Loss: 0.2949, Validation Loss: 0.2855, Train: 0.896, Validation: 0.895, Test: 0.899, AUC: 0.955\n",
      "Epoch: 6, Loss: 0.2786, Validation Loss: 0.2743, Train: 0.896, Validation: 0.895, Test: 0.899, AUC: 0.955\n",
      "Epoch: 7, Loss: 0.2701, Validation Loss: 0.2655, Train: 0.897, Validation: 0.897, Test: 0.899, AUC: 0.956\n",
      "Epoch: 8, Loss: 0.2655, Validation Loss: 0.2676, Train: 0.897, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 9, Loss: 0.2634, Validation Loss: 0.2613, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 10, Loss: 0.2624, Validation Loss: 0.2620, Train: 0.898, Validation: 0.897, Test: 0.900, AUC: 0.956\n",
      "Epoch: 11, Loss: 0.2619, Validation Loss: 0.2606, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.956\n",
      "Epoch: 12, Loss: 0.2615, Validation Loss: 0.2606, Train: 0.897, Validation: 0.896, Test: 0.898, AUC: 0.956\n",
      "Epoch: 13, Loss: 0.2608, Validation Loss: 0.2629, Train: 0.898, Validation: 0.897, Test: 0.900, AUC: 0.956\n",
      "Epoch: 14, Loss: 0.2603, Validation Loss: 0.2601, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 15, Loss: 0.2606, Validation Loss: 0.2617, Train: 0.897, Validation: 0.896, Test: 0.897, AUC: 0.956\n",
      "Epoch: 16, Loss: 0.2600, Validation Loss: 0.2608, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 17, Loss: 0.2601, Validation Loss: 0.2587, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.956\n",
      "Epoch: 18, Loss: 0.2595, Validation Loss: 0.2604, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.956\n",
      "Epoch: 19, Loss: 0.2592, Validation Loss: 0.2619, Train: 0.898, Validation: 0.896, Test: 0.900, AUC: 0.956\n",
      "Epoch: 20, Loss: 0.2595, Validation Loss: 0.2602, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.956\n",
      "Epoch: 21, Loss: 0.2591, Validation Loss: 0.2589, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 22, Loss: 0.2591, Validation Loss: 0.2634, Train: 0.898, Validation: 0.896, Test: 0.898, AUC: 0.956\n",
      "Epoch: 23, Loss: 0.2591, Validation Loss: 0.2603, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 24, Loss: 0.2581, Validation Loss: 0.2595, Train: 0.899, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 25, Loss: 0.2578, Validation Loss: 0.2579, Train: 0.898, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 26, Loss: 0.2570, Validation Loss: 0.2575, Train: 0.899, Validation: 0.898, Test: 0.900, AUC: 0.957\n",
      "Epoch: 27, Loss: 0.2570, Validation Loss: 0.2555, Train: 0.898, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 28, Loss: 0.2566, Validation Loss: 0.2541, Train: 0.898, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 29, Loss: 0.2564, Validation Loss: 0.2553, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.957\n",
      "Best epoch: \n",
      "Epoch: 29, Loss: 0.2564, Validation Loss: 0.2553, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.957\n",
      "\n",
      "The training took 504 seconds (8.40 minutes).\n",
      "------------------(1/1) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Epoch: 0, Loss: 1.2952, Validation Loss: 0.6265, Train: 0.575, Validation: 0.578, Test: 0.575, AUC: 0.741\n",
      "Epoch: 1, Loss: 0.5256, Validation Loss: 0.4548, Train: 0.830, Validation: 0.831, Test: 0.835, AUC: 0.919\n",
      "Epoch: 2, Loss: 0.4124, Validation Loss: 0.3751, Train: 0.878, Validation: 0.878, Test: 0.879, AUC: 0.944\n",
      "Epoch: 3, Loss: 0.3467, Validation Loss: 0.3225, Train: 0.888, Validation: 0.887, Test: 0.890, AUC: 0.949\n",
      "Epoch: 4, Loss: 0.3062, Validation Loss: 0.2926, Train: 0.893, Validation: 0.892, Test: 0.896, AUC: 0.953\n",
      "Epoch: 5, Loss: 0.2831, Validation Loss: 0.2778, Train: 0.896, Validation: 0.895, Test: 0.898, AUC: 0.955\n",
      "Epoch: 6, Loss: 0.2719, Validation Loss: 0.2667, Train: 0.897, Validation: 0.896, Test: 0.898, AUC: 0.955\n",
      "Epoch: 7, Loss: 0.2666, Validation Loss: 0.2669, Train: 0.897, Validation: 0.895, Test: 0.899, AUC: 0.955\n",
      "Epoch: 8, Loss: 0.2637, Validation Loss: 0.2605, Train: 0.897, Validation: 0.895, Test: 0.897, AUC: 0.955\n",
      "Epoch: 9, Loss: 0.2616, Validation Loss: 0.2587, Train: 0.898, Validation: 0.896, Test: 0.898, AUC: 0.956\n",
      "Epoch: 10, Loss: 0.2608, Validation Loss: 0.2611, Train: 0.898, Validation: 0.896, Test: 0.900, AUC: 0.956\n",
      "Epoch: 11, Loss: 0.2601, Validation Loss: 0.2594, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.956\n",
      "Epoch: 12, Loss: 0.2595, Validation Loss: 0.2603, Train: 0.899, Validation: 0.896, Test: 0.900, AUC: 0.956\n",
      "Epoch: 13, Loss: 0.2590, Validation Loss: 0.2588, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.957\n",
      "Epoch: 14, Loss: 0.2596, Validation Loss: 0.2584, Train: 0.899, Validation: 0.897, Test: 0.901, AUC: 0.957\n",
      "Epoch: 15, Loss: 0.2586, Validation Loss: 0.2611, Train: 0.899, Validation: 0.898, Test: 0.900, AUC: 0.957\n",
      "Epoch: 16, Loss: 0.2583, Validation Loss: 0.2561, Train: 0.899, Validation: 0.898, Test: 0.902, AUC: 0.957\n",
      "Epoch: 17, Loss: 0.2579, Validation Loss: 0.2544, Train: 0.900, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 18, Loss: 0.2579, Validation Loss: 0.2566, Train: 0.900, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 19, Loss: 0.2574, Validation Loss: 0.2563, Train: 0.899, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 20, Loss: 0.2574, Validation Loss: 0.2551, Train: 0.900, Validation: 0.898, Test: 0.900, AUC: 0.957\n",
      "Epoch: 21, Loss: 0.2576, Validation Loss: 0.2560, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 22, Loss: 0.2573, Validation Loss: 0.2588, Train: 0.900, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 23, Loss: 0.2568, Validation Loss: 0.2526, Train: 0.899, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 24, Loss: 0.2569, Validation Loss: 0.2577, Train: 0.899, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 25, Loss: 0.2570, Validation Loss: 0.2547, Train: 0.898, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 26, Loss: 0.2568, Validation Loss: 0.2536, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 27, Loss: 0.2566, Validation Loss: 0.2558, Train: 0.899, Validation: 0.897, Test: 0.900, AUC: 0.957\n",
      "Epoch: 28, Loss: 0.2563, Validation Loss: 0.2574, Train: 0.899, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 29, Loss: 0.2569, Validation Loss: 0.2546, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Best epoch: \n",
      "Epoch: 26, Loss: 0.2568, Validation Loss: 0.2536, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "\n",
      "The training took 562 seconds (9.37 minutes).\n",
      "------------------(1/1) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Epoch: 0, Loss: 2.2337, Validation Loss: 0.6544, Train: 0.568, Validation: 0.569, Test: 0.571, AUC: 0.755\n",
      "Epoch: 1, Loss: 0.5807, Validation Loss: 0.5247, Train: 0.714, Validation: 0.714, Test: 0.719, AUC: 0.876\n",
      "Epoch: 2, Loss: 0.4844, Validation Loss: 0.4456, Train: 0.815, Validation: 0.816, Test: 0.820, AUC: 0.928\n",
      "Epoch: 3, Loss: 0.4136, Validation Loss: 0.3817, Train: 0.869, Validation: 0.869, Test: 0.873, AUC: 0.941\n",
      "Epoch: 4, Loss: 0.3551, Validation Loss: 0.3292, Train: 0.887, Validation: 0.888, Test: 0.890, AUC: 0.950\n",
      "Epoch: 5, Loss: 0.3104, Validation Loss: 0.2937, Train: 0.893, Validation: 0.894, Test: 0.896, AUC: 0.953\n",
      "Epoch: 6, Loss: 0.2852, Validation Loss: 0.2774, Train: 0.897, Validation: 0.897, Test: 0.900, AUC: 0.955\n",
      "Epoch: 7, Loss: 0.2727, Validation Loss: 0.2674, Train: 0.898, Validation: 0.896, Test: 0.900, AUC: 0.955\n",
      "Epoch: 8, Loss: 0.2664, Validation Loss: 0.2612, Train: 0.898, Validation: 0.898, Test: 0.900, AUC: 0.956\n",
      "Epoch: 9, Loss: 0.2634, Validation Loss: 0.2635, Train: 0.898, Validation: 0.898, Test: 0.901, AUC: 0.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.2614, Validation Loss: 0.2593, Train: 0.899, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 11, Loss: 0.2607, Validation Loss: 0.2587, Train: 0.899, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 12, Loss: 0.2602, Validation Loss: 0.2608, Train: 0.899, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 13, Loss: 0.2595, Validation Loss: 0.2613, Train: 0.897, Validation: 0.896, Test: 0.899, AUC: 0.957\n",
      "Epoch: 14, Loss: 0.2592, Validation Loss: 0.2594, Train: 0.898, Validation: 0.897, Test: 0.899, AUC: 0.957\n",
      "Epoch: 15, Loss: 0.2583, Validation Loss: 0.2560, Train: 0.899, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 16, Loss: 0.2583, Validation Loss: 0.2591, Train: 0.898, Validation: 0.896, Test: 0.899, AUC: 0.957\n",
      "Epoch: 17, Loss: 0.2578, Validation Loss: 0.2600, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 18, Loss: 0.2581, Validation Loss: 0.2590, Train: 0.898, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 19, Loss: 0.2577, Validation Loss: 0.2572, Train: 0.899, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 20, Loss: 0.2575, Validation Loss: 0.2545, Train: 0.899, Validation: 0.899, Test: 0.900, AUC: 0.957\n",
      "Epoch: 21, Loss: 0.2569, Validation Loss: 0.2535, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 22, Loss: 0.2566, Validation Loss: 0.2534, Train: 0.900, Validation: 0.900, Test: 0.901, AUC: 0.957\n",
      "Epoch: 23, Loss: 0.2568, Validation Loss: 0.2565, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 24, Loss: 0.2573, Validation Loss: 0.2539, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.957\n",
      "Epoch: 25, Loss: 0.2565, Validation Loss: 0.2587, Train: 0.899, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 26, Loss: 0.2560, Validation Loss: 0.2587, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 27, Loss: 0.2564, Validation Loss: 0.2565, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 28, Loss: 0.2561, Validation Loss: 0.2584, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 29, Loss: 0.2561, Validation Loss: 0.2551, Train: 0.898, Validation: 0.898, Test: 0.900, AUC: 0.957\n",
      "Best epoch: \n",
      "Epoch: 22, Loss: 0.2566, Validation Loss: 0.2534, Train: 0.900, Validation: 0.900, Test: 0.901, AUC: 0.957\n",
      "\n",
      "The training took 589 seconds (9.82 minutes).\n",
      "------------------(1/1) models trained------------------\n",
      "\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Epoch: 0, Loss: 0.8841, Validation Loss: 0.5310, Train: 0.683, Validation: 0.685, Test: 0.688, AUC: 0.864\n",
      "Epoch: 1, Loss: 0.4877, Validation Loss: 0.4385, Train: 0.824, Validation: 0.822, Test: 0.826, AUC: 0.928\n",
      "Epoch: 2, Loss: 0.3912, Validation Loss: 0.3502, Train: 0.879, Validation: 0.877, Test: 0.881, AUC: 0.944\n",
      "Epoch: 3, Loss: 0.3242, Validation Loss: 0.3062, Train: 0.890, Validation: 0.889, Test: 0.892, AUC: 0.953\n",
      "Epoch: 4, Loss: 0.2914, Validation Loss: 0.2807, Train: 0.896, Validation: 0.895, Test: 0.897, AUC: 0.954\n",
      "Epoch: 5, Loss: 0.2748, Validation Loss: 0.2653, Train: 0.897, Validation: 0.895, Test: 0.900, AUC: 0.956\n",
      "Epoch: 6, Loss: 0.2669, Validation Loss: 0.2657, Train: 0.899, Validation: 0.897, Test: 0.900, AUC: 0.956\n",
      "Epoch: 7, Loss: 0.2634, Validation Loss: 0.2650, Train: 0.896, Validation: 0.895, Test: 0.897, AUC: 0.956\n",
      "Epoch: 8, Loss: 0.2609, Validation Loss: 0.2585, Train: 0.898, Validation: 0.898, Test: 0.899, AUC: 0.957\n",
      "Epoch: 9, Loss: 0.2600, Validation Loss: 0.2619, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 10, Loss: 0.2591, Validation Loss: 0.2595, Train: 0.899, Validation: 0.898, Test: 0.901, AUC: 0.957\n",
      "Epoch: 11, Loss: 0.2588, Validation Loss: 0.2550, Train: 0.899, Validation: 0.899, Test: 0.902, AUC: 0.957\n",
      "Epoch: 12, Loss: 0.2590, Validation Loss: 0.2548, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 13, Loss: 0.2582, Validation Loss: 0.2573, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 14, Loss: 0.2575, Validation Loss: 0.2561, Train: 0.899, Validation: 0.899, Test: 0.900, AUC: 0.957\n",
      "Epoch: 15, Loss: 0.2581, Validation Loss: 0.2576, Train: 0.900, Validation: 0.899, Test: 0.901, AUC: 0.957\n",
      "Epoch: 16, Loss: 0.2572, Validation Loss: 0.2562, Train: 0.900, Validation: 0.899, Test: 0.900, AUC: 0.957\n",
      "Epoch: 17, Loss: 0.2569, Validation Loss: 0.2538, Train: 0.900, Validation: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 18, Loss: 0.2568, Validation Loss: 0.2542, Train: 0.900, Validation: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 19, Loss: 0.2565, Validation Loss: 0.2564, Train: 0.899, Validation: 0.899, Test: 0.900, AUC: 0.958\n",
      "Epoch: 20, Loss: 0.2565, Validation Loss: 0.2524, Train: 0.901, Validation: 0.900, Test: 0.902, AUC: 0.958\n",
      "Epoch: 21, Loss: 0.2567, Validation Loss: 0.2547, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.958\n",
      "Epoch: 22, Loss: 0.2559, Validation Loss: 0.2527, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.958\n",
      "Epoch: 23, Loss: 0.2551, Validation Loss: 0.2560, Train: 0.900, Validation: 0.899, Test: 0.900, AUC: 0.958\n",
      "Epoch: 24, Loss: 0.2545, Validation Loss: 0.2520, Train: 0.901, Validation: 0.900, Test: 0.903, AUC: 0.958\n",
      "Epoch: 25, Loss: 0.2541, Validation Loss: 0.2515, Train: 0.900, Validation: 0.899, Test: 0.902, AUC: 0.958\n",
      "Epoch: 26, Loss: 0.2538, Validation Loss: 0.2565, Train: 0.899, Validation: 0.898, Test: 0.900, AUC: 0.958\n",
      "Epoch: 27, Loss: 0.2539, Validation Loss: 0.2528, Train: 0.900, Validation: 0.900, Test: 0.902, AUC: 0.958\n",
      "Epoch: 28, Loss: 0.2534, Validation Loss: 0.2576, Train: 0.900, Validation: 0.900, Test: 0.903, AUC: 0.958\n",
      "Epoch: 29, Loss: 0.2535, Validation Loss: 0.2576, Train: 0.901, Validation: 0.900, Test: 0.903, AUC: 0.958\n",
      "Best epoch: \n",
      "Epoch: 24, Loss: 0.2545, Validation Loss: 0.2520, Train: 0.901, Validation: 0.900, Test: 0.903, AUC: 0.958\n",
      "\n",
      "The training took 561 seconds (9.35 minutes).\n",
      "------------------(1/1) models trained------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "\n",
    "paramList = [(16, 1, 0), # node_hiddenfeats, #num_messagepasses, #dropout\n",
    "          (16, 1, 0.3),\n",
    "          (16, 1, 0.5),\n",
    "          (32, 1, 0),\n",
    "          (32, 1, 0.3),\n",
    "          (32, 1, 0.5),\n",
    "          (64, 1, 0),\n",
    "          (64, 1, 0.3),\n",
    "          (64, 1, 0.5),\n",
    "          (16, 2, 0), \n",
    "          (16, 2, 0.3),\n",
    "          (16, 2, 0.5),\n",
    "          (32, 2, 0),\n",
    "          (32, 2, 0.3),\n",
    "          (32, 2, 0.5),\n",
    "          (64, 2, 0),\n",
    "          (64, 2, 0.3),\n",
    "          (64, 2, 0.5),\n",
    "          (16, 3, 0), \n",
    "          (16, 3, 0.3),\n",
    "          (16, 3, 0.5),\n",
    "          (32, 3, 0),\n",
    "          (32, 3, 0.3),\n",
    "          (32, 3, 0.5),\n",
    "          (64, 3, 0),\n",
    "          (64, 3, 0.3),\n",
    "          (64, 3, 0.5),\n",
    "          (16, 5, 0), \n",
    "          (16, 5, 0.3),\n",
    "          (16, 5, 0.5),\n",
    "          (32, 5, 0),\n",
    "          (32, 5, 0.3),\n",
    "          (32, 5, 0.5),\n",
    "          (64, 5, 0),\n",
    "          (64, 5, 0.3),\n",
    "          (64, 5, 0.5)]\n",
    "\n",
    "batchSize = 1024\n",
    "print(f'Device: {device}')\n",
    "\n",
    "for n_hidden, msgpasses, dropout in paramList:\n",
    "    for i in range(len(datasetDirs)):\n",
    "        dataset = TauGraphDataset(datasetNames[i], datasetDirs[i])\n",
    "        splitIndices = dataset.get_split_indices()\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(splitIndices['train'])\n",
    "        val_sampler = SubsetRandomSampler(splitIndices['valid'])\n",
    "        test_sampler = SubsetRandomSampler(splitIndices['test'])\n",
    "\n",
    "        train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=batchSize, drop_last=False)\n",
    "        val_dataloader = GraphDataLoader(dataset, sampler=val_sampler, batch_size=batchSize, drop_last=False)\n",
    "        test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=batchSize, drop_last=False)\n",
    "\n",
    "        # Create the model with given dimensions\n",
    "        model = CustomGCN_OnlyNFeatSumMsg(dataset.dim_nfeats, n_hidden, dataset.num_graph_classes, msgpasses, dropout).to(device)\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        epochs = 30\n",
    "\n",
    "        # train\n",
    "        print(f'Beginning training on dataset {datasetNames[i]}')\n",
    "        results, bestmodel = trainEpochs(model, device, train_dataloader, optimizer, loss_fn, batchSize, epochs)\n",
    "        results.printBestResult()\n",
    "\n",
    "        # save results\n",
    "        outputFolder = path.join(datasetDirs[i], f'Output_CustomGCN_OnlyNFeatSumMsg_NHiddenFeat_{n_hidden}_MsgPasses_{msgpasses}_Dropout_{dropout}')\n",
    "        Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results.savePlots(outputFolder)\n",
    "        results.dumpSummary(outputFolder)\n",
    "        results.pickledump(outputFolder)\n",
    "\n",
    "        # save the best model for inference. (when loading for inference -> model.eval()!! )\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "        torch.save(bestmodel.state_dict(), path.join(outputFolder, 'model.pt'))\n",
    "\n",
    "        print(f'------------------({i+1}/{len(datasetDirs)}) models trained------------------\\n')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - now\n",
    "print(f'{elapsed} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "\n",
    "paramList = [(16, 1, 0), # node_hiddenfeats, #num_messagepasses, #dropout\n",
    "          (16, 1, 0.3),\n",
    "          (16, 1, 0.5),\n",
    "          (32, 1, 0),\n",
    "          (32, 1, 0.3),\n",
    "          (32, 1, 0.5),\n",
    "          (64, 1, 0),\n",
    "          (64, 1, 0.3),\n",
    "          (64, 1, 0.5),\n",
    "          (16, 2, 0), \n",
    "          (16, 2, 0.3),\n",
    "          (16, 2, 0.5),\n",
    "          (32, 2, 0),\n",
    "          (32, 2, 0.3),\n",
    "          (32, 2, 0.5),\n",
    "          (64, 2, 0),\n",
    "          (64, 2, 0.3),\n",
    "          (64, 2, 0.5),\n",
    "          (16, 3, 0), \n",
    "          (16, 3, 0.3),\n",
    "          (16, 3, 0.5),\n",
    "          (32, 3, 0),\n",
    "          (32, 3, 0.3),\n",
    "          (32, 3, 0.5),\n",
    "          (64, 3, 0),\n",
    "          (64, 3, 0.3),\n",
    "          (64, 3, 0.5),\n",
    "          (16, 5, 0), \n",
    "          (16, 5, 0.3),\n",
    "          (16, 5, 0.5),\n",
    "          (32, 5, 0),\n",
    "          (32, 5, 0.3),\n",
    "          (32, 5, 0.5),\n",
    "          (64, 5, 0),\n",
    "          (64, 5, 0.3),\n",
    "          (64, 5, 0.5)]\n",
    "\n",
    "batchSize = 1024\n",
    "print(f'Device: {device}')\n",
    "\n",
    "for n_hidden, msgpasses, dropout in paramList:\n",
    "    for i in range(len(datasetDirs)):\n",
    "        dataset = TauGraphDataset(datasetNames[i], datasetDirs[i])\n",
    "        splitIndices = dataset.get_split_indices()\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(splitIndices['train'])\n",
    "        val_sampler = SubsetRandomSampler(splitIndices['valid'])\n",
    "        test_sampler = SubsetRandomSampler(splitIndices['test'])\n",
    "\n",
    "        train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=batchSize, drop_last=False)\n",
    "        val_dataloader = GraphDataLoader(dataset, sampler=val_sampler, batch_size=batchSize, drop_last=False)\n",
    "        test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=batchSize, drop_last=False)\n",
    "\n",
    "        # Create the model with given dimensions\n",
    "        model = CustomGCN_OnlyNFeatMeanMsg(dataset.dim_nfeats, n_hidden, dataset.num_graph_classes, msgpasses, dropout).to(device)\n",
    "        model.reset_parameters()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        epochs = 30\n",
    "\n",
    "        # train\n",
    "        print(f'Beginning training on dataset {datasetNames[i]}')\n",
    "        results, bestmodel = trainEpochs(model, device, train_dataloader, optimizer, loss_fn, batchSize, epochs)\n",
    "        results.printBestResult()\n",
    "\n",
    "        # save results\n",
    "        outputFolder = path.join(datasetDirs[i], f'Output_CustomGCN_OnlyNFeatMeanMsg_NHiddenFeat_{n_hidden}_MsgPasses_{msgpasses}_Dropout_{dropout}')\n",
    "        Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results.savePlots(outputFolder)\n",
    "        results.dumpSummary(outputFolder)\n",
    "        results.pickledump(outputFolder)\n",
    "\n",
    "        # save the best model for inference. (when loading for inference -> model.eval()!! )\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "        torch.save(bestmodel.state_dict(), path.join(outputFolder, 'model.pt'))\n",
    "\n",
    "        print(f'------------------({i+1}/{len(datasetDirs)}) models trained------------------\\n')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - now\n",
    "print(f'{elapsed} seconds elapsed')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e711687f31016629c64c84d23d27d9292aefc640ef90f9639fb07f22fea1b3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
