{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dgl\n",
    "import copy\n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import awkward as ak\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from trainresults import TrainResults\n",
    "from train_eval_func import train, evaluate\n",
    "from copy import deepcopy\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from TauGraphDatasetInfo import TauGraphDatasetInfo\n",
    "from CustomGCNs import CustomGCN_OnlyNFeatSumMsg, CustomGCN_OnlyNFeatMeanMsg\n",
    "from TauGraphDataset import TauGraphDataset, GetNodeFeatureVectors, GetEdgeFeatureVectors, GetNeighborNodes, GetEdgeList\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def trainEpochs(model, device, dataloader, optimizer, loss_fn, batchsize, nEpochs):\n",
    "    results = TrainResults()\n",
    "    bestModel = None\n",
    "    bestTestAcc = 0.0\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        # train\n",
    "        epochLoss = train(model, device, dataloader, optimizer, loss_fn, batchsize, results)\n",
    "\n",
    "        # evaluate\n",
    "        train_result = evaluate(model, device, train_dataloader)\n",
    "        test_result = evaluate(model, device, test_dataloader)\n",
    "\n",
    "        results.addEpochResult(epochLoss, train_result, test_result)\n",
    "        results.printLastResult()\n",
    "\n",
    "        if results.best_test_acc > bestTestAcc:\n",
    "            bestValAcc = results.best_test_acc\n",
    "            bestModel = copy.deepcopy(model)\n",
    "\n",
    "    return results, bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetNames(datasetDir):\n",
    "    files = glob.glob(datasetDir + '/*.json', recursive=True)\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "['/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n",
      "['Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "\n",
    "datasetDir = '/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets'\n",
    "datasetDirs, datasetNames = getDatasetNames(datasetDir)\n",
    "print(datasetDirs)\n",
    "print(datasetNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetName = datasetNames[0]\n",
    "datasetDir = datasetDirs[0]\n",
    "dataset = TauGraphDataset(datasetName, datasetDir)\n",
    "dataset.printProperties()\n",
    "\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'Label: {label}')\n",
    "print(GetNodeFeatureVectors(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Done loading data from cached files.\n",
      "Beginning training on dataset Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Epoch: 0, Loss: 1.1228, Train: 0.835, Test: 0.837, AUC: 0.937\n",
      "Epoch: 1, Loss: 0.3697, Train: 0.889, Test: 0.889, AUC: 0.944\n",
      "Epoch: 2, Loss: 0.3207, Train: 0.891, Test: 0.891, AUC: 0.948\n",
      "Epoch: 3, Loss: 0.2976, Train: 0.893, Test: 0.894, AUC: 0.952\n",
      "Epoch: 4, Loss: 0.2866, Train: 0.896, Test: 0.896, AUC: 0.953\n",
      "Epoch: 5, Loss: 0.2813, Train: 0.889, Test: 0.889, AUC: 0.953\n",
      "Epoch: 6, Loss: 0.2792, Train: 0.894, Test: 0.894, AUC: 0.953\n",
      "Epoch: 7, Loss: 0.2769, Train: 0.896, Test: 0.896, AUC: 0.953\n",
      "Epoch: 8, Loss: 0.2773, Train: 0.884, Test: 0.884, AUC: 0.953\n",
      "Epoch: 9, Loss: 0.2761, Train: 0.898, Test: 0.898, AUC: 0.955\n",
      "Epoch: 10, Loss: 0.2725, Train: 0.897, Test: 0.898, AUC: 0.955\n",
      "Epoch: 11, Loss: 0.2706, Train: 0.897, Test: 0.898, AUC: 0.955\n",
      "Epoch: 12, Loss: 0.2710, Train: 0.898, Test: 0.899, AUC: 0.956\n",
      "Epoch: 13, Loss: 0.2696, Train: 0.898, Test: 0.898, AUC: 0.956\n",
      "Epoch: 14, Loss: 0.2653, Train: 0.898, Test: 0.898, AUC: 0.956\n",
      "Epoch: 15, Loss: 0.2640, Train: 0.898, Test: 0.898, AUC: 0.956\n",
      "Epoch: 16, Loss: 0.2639, Train: 0.897, Test: 0.897, AUC: 0.956\n",
      "Epoch: 17, Loss: 0.2634, Train: 0.898, Test: 0.898, AUC: 0.956\n",
      "Epoch: 18, Loss: 0.2613, Train: 0.896, Test: 0.896, AUC: 0.956\n",
      "Epoch: 19, Loss: 0.2631, Train: 0.890, Test: 0.890, AUC: 0.956\n",
      "Epoch: 20, Loss: 0.2608, Train: 0.897, Test: 0.897, AUC: 0.956\n",
      "Epoch: 21, Loss: 0.2612, Train: 0.893, Test: 0.894, AUC: 0.956\n",
      "Epoch: 22, Loss: 0.2628, Train: 0.898, Test: 0.898, AUC: 0.956\n",
      "Epoch: 23, Loss: 0.2609, Train: 0.895, Test: 0.895, AUC: 0.956\n",
      "Epoch: 24, Loss: 0.2588, Train: 0.899, Test: 0.899, AUC: 0.958\n",
      "Epoch: 25, Loss: 0.2594, Train: 0.899, Test: 0.900, AUC: 0.958\n",
      "Epoch: 26, Loss: 0.2586, Train: 0.898, Test: 0.900, AUC: 0.958\n",
      "Epoch: 27, Loss: 0.2587, Train: 0.898, Test: 0.899, AUC: 0.958\n",
      "Epoch: 28, Loss: 0.2584, Train: 0.894, Test: 0.894, AUC: 0.958\n",
      "Epoch: 29, Loss: 0.2578, Train: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 30, Loss: 0.2563, Train: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 31, Loss: 0.2564, Train: 0.898, Test: 0.899, AUC: 0.958\n",
      "Epoch: 32, Loss: 0.2553, Train: 0.900, Test: 0.900, AUC: 0.958\n",
      "Epoch: 33, Loss: 0.2555, Train: 0.897, Test: 0.898, AUC: 0.958\n",
      "Epoch: 34, Loss: 0.2559, Train: 0.898, Test: 0.898, AUC: 0.958\n",
      "Epoch: 35, Loss: 0.2550, Train: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 36, Loss: 0.2548, Train: 0.899, Test: 0.899, AUC: 0.958\n",
      "Epoch: 37, Loss: 0.2556, Train: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 38, Loss: 0.2549, Train: 0.900, Test: 0.901, AUC: 0.958\n",
      "Epoch: 39, Loss: 0.2537, Train: 0.901, Test: 0.902, AUC: 0.958\n",
      "Epoch: 40, Loss: 0.2541, Train: 0.901, Test: 0.902, AUC: 0.959\n",
      "Epoch: 41, Loss: 0.2543, Train: 0.901, Test: 0.900, AUC: 0.959\n",
      "Epoch: 42, Loss: 0.2531, Train: 0.902, Test: 0.901, AUC: 0.959\n",
      "Epoch: 43, Loss: 0.2521, Train: 0.900, Test: 0.899, AUC: 0.959\n",
      "Epoch: 44, Loss: 0.2526, Train: 0.901, Test: 0.901, AUC: 0.959\n",
      "Epoch: 45, Loss: 0.2525, Train: 0.900, Test: 0.901, AUC: 0.959\n",
      "Epoch: 46, Loss: 0.2534, Train: 0.902, Test: 0.902, AUC: 0.959\n",
      "Epoch: 47, Loss: 0.2516, Train: 0.900, Test: 0.899, AUC: 0.959\n",
      "Epoch: 48, Loss: 0.2529, Train: 0.899, Test: 0.901, AUC: 0.959\n",
      "Epoch: 49, Loss: 0.2524, Train: 0.901, Test: 0.900, AUC: 0.959\n",
      "Best epoch: \n",
      "Epoch: 40, Loss: 0.2541, Train: 0.901, Test: 0.902, AUC: 0.959\n",
      "------------------(1/1) models trained------------------\n",
      "\n",
      "1095.1496250629425 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "\n",
    "batchSize = 1024\n",
    "print(f'Device: {device}')\n",
    "\n",
    "for i in range(len(datasetDirs)):\n",
    "    trainingStart = time.time()\n",
    "    \n",
    "    dataset = TauGraphDataset(datasetNames[i], datasetDirs[i])\n",
    "    splitIndices = dataset.get_split_indices()\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(splitIndices['train'])\n",
    "    test_sampler = SubsetRandomSampler(splitIndices['test'])\n",
    "\n",
    "    train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=batchSize, drop_last=False)\n",
    "    test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=batchSize, drop_last=False)\n",
    "    \n",
    "    # Create the model with given dimensions\n",
    "    model = CustomGCN_OnlyNFeatSumMsg(dataset.dim_nfeats, 16, dataset.num_graph_classes).to(device)\n",
    "    model.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 50\n",
    "    \n",
    "    # train\n",
    "    print(f'Beginning training on dataset {datasetNames[i]}')\n",
    "    results, bestmodel = trainEpochs(model, device, train_dataloader, optimizer, loss_fn, batchSize, epochs)\n",
    "    results.printBestResult()\n",
    "    \n",
    "    # save results\n",
    "    outputFolder = path.join(datasetDirs[i], 'Output_CustomGCN_OnlyNFeatSumMsg')\n",
    "    Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    trainingElapsed= time.time() - trainingStart\n",
    "    results.savePlots(outputFolder)\n",
    "    results.dumpSummary(outputFolder, trainingElapsed)\n",
    "    results.pickledump(outputFolder)\n",
    "    \n",
    "    # save the best model for inference. (when loading for inference -> model.eval()!! )\n",
    "    # https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict\n",
    "    torch.save(bestmodel.state_dict(), path.join(outputFolder, 'model.pt'))\n",
    "    \n",
    "    print(f'------------------({i+1}/{len(datasetDirs)}) models trained------------------\\n')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - now\n",
    "print(f'{elapsed} seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e711687f31016629c64c84d23d27d9292aefc640ef90f9639fb07f22fea1b3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
