{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dgl\n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from trainresults import TrainResults\n",
    "from train_eval_func import train, evaluate\n",
    "from copy import deepcopy\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from TauGraphDatasetInfo import TauGraphDatasetInfo\n",
    "from TauGraphDataset import TauGraphDataset, GetNodeFeatureVectors, GetEdgeFeatureVectors\n",
    "from TauGraphDataset import GetNeighborNodes, GetEdgeList, GetEdgeFeatureVectorsFromSourceNode, Graph2FlatZeropaddedList\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetNames(datasetDir):\n",
    "    files = glob.glob(datasetDir + '/*.json', recursive=True)\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n",
      "['Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n"
     ]
    }
   ],
   "source": [
    "datasetDir = '/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets'\n",
    "datasetDirs, datasetNames = getDatasetNames(datasetDir)\n",
    "print(datasetDirs)\n",
    "print(datasetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "<TauGraphDataset.TauGraphDataset object at 0x7f958ea3c710>\n"
     ]
    }
   ],
   "source": [
    "dataset = TauGraphDataset(datasetNames[0], datasetDirs[0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Graphs_DYJetsToLL_M-50_genuineTaus_and_jets,\n",
      " directory: /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "label: 1\n",
      "graph classes: ['0', '1']\n",
      "dataset graph count: 200000\n",
      "nodeFeatKeys: ['pt', 'eta', 'phi', 'mass', 'charge', 'particleType', 'summand']\n",
      "edgeFeatKeys: ['deltaEta', 'deltaPhi', 'deltaR']\n",
      "graphFeatkeys: ['nodeCount']\n",
      "max node count: 81\n",
      "min node count: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'name: {datasetNames[0]},\\n directory: {datasetDirs[0]}')\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'label: {label}')\n",
    "print(f'graph classes: {dataset.graphClasses}')\n",
    "print(f'dataset graph count: {dataset.num_graphs}')\n",
    "print(f'nodeFeatKeys: {dataset.nodeFeatKeys}')\n",
    "print(f'edgeFeatKeys: {dataset.edgeFeatKeys}')\n",
    "print(f'graphFeatkeys: {dataset.graphFeatKeys}')\n",
    "print(f'max node count: {dataset.maxNodeCount}')\n",
    "print(f'min node count: {dataset.minNodeCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "nFeatDim: 7\n",
      "eFeatDim: 3\n",
      "maxNodeCount: 81\n",
      "\n",
      "node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\n",
      " nFeatDim + eFeatDim * (maxNodeCount-1) = 7 + 3 * 80 =  247\n",
      "The (maxNodeCount-1) comes from fully connected graphs without self-loops\n",
      "\n",
      "only node features dim per Node: nFeatDim=7\n",
      "\n",
      "node + edge features with zero padding to fill until maxNodeCount leads to inputsize: 20007\n",
      "check example: node + edge features list size: 20007\n",
      "\n",
      "only node features with zero padding to fill until maxNodeCount leads to inputsize: 567\n",
      "check example: only node features list size: 567\n"
     ]
    }
   ],
   "source": [
    "graphs, labels = dataset[:]\n",
    "g = graphs[0]\n",
    "nFeatDim = dataset.dim_nfeats\n",
    "eFeatDim = dataset.dim_efeats\n",
    "maxNodeCount = dataset.maxNodeCount\n",
    "print(g)\n",
    "print(f'nFeatDim: {nFeatDim}')\n",
    "print(f'eFeatDim: {eFeatDim}')\n",
    "print(f'maxNodeCount: {maxNodeCount}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDim = nFeatDim + eFeatDim * (maxNodeCount - 1)\n",
    "print(f'node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\\n',\n",
    "      f'nFeatDim + eFeatDim * (maxNodeCount-1) = {nFeatDim} + {eFeatDim} * {maxNodeCount - 1} = ',\n",
    "      f'{nodeAndEdgeFeaturePaddedDim}')\n",
    "print(f'The (maxNodeCount-1) comes from fully connected graphs without self-loops')\n",
    "print()\n",
    "print(f'only node features dim per Node: nFeatDim={nFeatDim}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDimInputSize = nodeAndEdgeFeaturePaddedDim * maxNodeCount\n",
    "nodeFeaturePaddedDimInputSize = nFeatDim * maxNodeCount\n",
    "print(f'node + edge features with zero padding to fill until maxNodeCount leads to inputsize: {nodeAndEdgeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = True\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: node + edge features list size: {len(temp)}')\n",
    "print()\n",
    "print(f'only node features with zero padding to fill until maxNodeCount leads to inputsize: {nodeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = False\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: only node features list size: {len(temp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputData(dgldataset, useEdgeFeatures):\n",
    "    inputs = [] \n",
    "    graphs, labels = dgldataset[:]\n",
    "    maxNodeCount = dgldataset.maxNodeCount\n",
    "    nFeatDim = dgldataset.dim_nfeats\n",
    "    eFeatDim = dgldataset.dim_efeats\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    it = 0\n",
    "    \n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        inputs.append(Graph2FlatZeropaddedList(graphs[i], nFeatDim, eFeatDim, maxNodeCount, useEdgeFeatures))\n",
    "\n",
    "    # Stack all inputs_ vertically\n",
    "    print(type(inputs))\n",
    "    inputs = np.array(inputs, dtype=np.float32)\n",
    "    print(\"before vstack - Input shape: \", inputs.shape)\n",
    "    print(inputs)\n",
    "    print(type(inputs))\n",
    "    inputs = np.vstack(inputs)\n",
    "    print(inputs)\n",
    "    \n",
    "\n",
    "    # Stack all labels_ horizontally\n",
    "    labels = np.hstack(labels)\n",
    "\n",
    "    print(\"Input shape: \", inputs.shape)\n",
    "    print(\"Labels shape: \", labels.shape)\n",
    "\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    print(labels.shape)\n",
    "    print(labels[0])\n",
    "    end = time.time() - start\n",
    "    print(f'graphs to flattened zero padded list took {end:.2f} seconds ({end/60:.2f} minutes)')\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [16:02<00:00, 207.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "before vstack - Input shape:  (200000, 20007)\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "Input shape:  (200000, 20007)\n",
      "Labels shape:  (200000,)\n",
      "(200000, 2)\n",
      "[0. 1.]\n",
      "graphs to flattened zero padded list took 992.24 seconds (16.54 minutes)\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = getInputData(dataset, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenerator(inputs, labels, batchsize):\n",
    "    while True:\n",
    "        start = 0\n",
    "        end = batchsize\n",
    "\n",
    "        while start  < len(inputs): \n",
    "            # load your images from numpy arrays or read from directory\n",
    "            x = inputs[start:end] \n",
    "            y = labels[start:end]\n",
    "            yield x, y\n",
    "\n",
    "            start += batchsize\n",
    "            end += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"KerasModel_NodeAndEdgeFeat\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 32)                640256    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 652,850\n",
      "Trainable params: 652,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"KerasModel_NodeAndEdgeFeat\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 32)                640256    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 652,850\n",
      "Trainable params: 652,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "outputFolder = path.join(datasetDir, 'Output_Keras_NodeAndEdgeFeat')\n",
    "Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model = keras.Sequential(name=\"KerasModel_NodeAndEdgeFeat\")\n",
    "inputDim = (nFeatDim + eFeatDim * (maxNodeCount - 1)) * maxNodeCount\n",
    "model.add(keras.layers.InputLayer(input_shape=(inputDim,), name=\"input\"))\n",
    "model.add(keras.layers.Dense(32, activation='relu', name=\"dense1\"))\n",
    "model.add(keras.layers.Dense(16*16, activation='relu', name=\"dense2\"))\n",
    "model.add(keras.layers.Dense(16, activation='relu', name=\"dense3\"))\n",
    "model.add(keras.layers.Dense(2, activation='softmax', name=\"output\"))\n",
    "model.summary()\n",
    "\n",
    "lossfunction = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, min_delta=0.0005)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path.join(outputFolder,'keras_nodeAndEdgeFeat_bestmodel.h5'), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "csvlogger = tf.keras.callbacks.CSVLogger(filename=path.join(outputFolder, 'results_keras_nodeAndEdgeFeat_bestmodel.csv'), separator=',', append=False)\n",
    "callbacks = [earlystopping, modelcheckpoint, csvlogger]\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss=lossfunction, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 160000\n",
      "validation samples: 30000\n",
      "test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_testAndVal, y_train, y_testAndVal = train_test_split(inputs, labels, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testAndVal, y_testAndVal, test_size=0.25, shuffle=False)\n",
    "print(f'train samples: {len(X_train)}')\n",
    "print(f'validation samples: {len(X_val)}')\n",
    "print(f'test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "156/156 [==============================] - 35s 223ms/step - loss: 0.2750 - accuracy: 0.8894 - val_loss: 0.2406 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24061, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 2/100000\n",
      "156/156 [==============================] - 34s 220ms/step - loss: 0.2431 - accuracy: 0.9048 - val_loss: 0.2353 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24061 to 0.23528, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 3/100000\n",
      "156/156 [==============================] - 34s 222ms/step - loss: 0.2379 - accuracy: 0.9066 - val_loss: 0.2325 - val_accuracy: 0.9107\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23528 to 0.23253, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 4/100000\n",
      "156/156 [==============================] - 34s 221ms/step - loss: 0.2338 - accuracy: 0.9083 - val_loss: 0.2306 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23253 to 0.23059, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 5/100000\n",
      "156/156 [==============================] - 35s 223ms/step - loss: 0.2302 - accuracy: 0.9095 - val_loss: 0.2293 - val_accuracy: 0.9109\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23059 to 0.22932, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 6/100000\n",
      " 76/156 [=============>................] - ETA: 15s - loss: 0.2307 - accuracy: 0.9089"
     ]
    }
   ],
   "source": [
    "batchsize=1024\n",
    "history = model.fit(\n",
    "    x = datagenerator(X_train, y_train, batchsize=batchsize),\n",
    "    validation_data = datagenerator(X_val, y_val,batchsize=batchsize),\n",
    "    steps_per_epoch = len(X_train)//batchsize,\n",
    "    validation_steps = len(X_val)//batchsize,\n",
    "    shuffle=False, # at creation from rootfiles -> graphs already shuffled dataset\n",
    "    epochs = 100000, # doesnt matter, since we use early stopping\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN output plot\n",
    "predictions = model.predict(X_test)\n",
    "#print(predictions)\n",
    "\n",
    "# TODO: check which order is actually signal (genuineTau) and which are background (fakeTau)\n",
    "genuineTau_decisions = predictions[:,0]\n",
    "fakeTau_decisions = predictions[:,1]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.hist(genuineTau_decisions, label='Genuine Taus', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, # normalize to form a probability density\n",
    "        linewidth=lw)\n",
    "plt.hist(fakeTau_decisions, label='Jets', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, linewidth=lw) # normalize to form a probability density\n",
    "plt.xlabel('Neural Network output') # add x-axis label\n",
    "plt.ylabel('Arbitrary units') # add y-axis label\n",
    "plt.legend() # add legend\n",
    "plt.savefig(path.join(outputFolder, \"NN_output.png\"))\n",
    "plt.clf()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# most tutorials slice the prediction for whatever reason with [:,1] but why?\n",
    "# predictions_ = predictions[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test.argmax(axis=1), predictions[:, 1])\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "roc_auc = auc(fpr, tpr) # area under curve (AUC), ROC = Receiver operating characteristic\n",
    "plt.plot(fpr, tpr, label='ROC (area = %0.2f)'%(roc_auc), linewidth=lw) # plot test ROC curve\n",
    "plt.plot([0, 1], # x from 0 to 1\n",
    "         [0, 1], # y from 0 to 1\n",
    "         '--', # dashed line\n",
    "         color='red', label='Luck', linewidth=lw)\n",
    "\n",
    "plt.xlabel('False Positive Rate') # x-axis label\n",
    "plt.ylabel('True Positive Rate') # y-axis label\n",
    "plt.title('Receiver operating characteristic (ROC) curve') # title\n",
    "plt.legend() # add legend\n",
    "plt.grid() # add grid\n",
    "plt.savefig(path.join(outputFolder, \"ROC_Curve.png\"))\n",
    "plt.clf()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(history.history)\n",
    "\n",
    "# Plot accuracy of NN\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='best')\n",
    "plt.savefig(path.join(outputFolder, \"model_accuracy.png\"))\n",
    "plt.clf()\n",
    "# Plot loss of NN\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='best')\n",
    "plt.savefig(path.join(outputFolder, \"model_loss.png\"))\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e711687f31016629c64c84d23d27d9292aefc640ef90f9639fb07f22fea1b3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
