{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dgl\n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from trainresults import TrainResults\n",
    "from train_eval_func import train, evaluate\n",
    "from copy import deepcopy\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from TauGraphDatasetInfo import TauGraphDatasetInfo\n",
    "from TauGraphDataset import TauGraphDataset, GetNodeFeatureVectors, GetEdgeFeatureVectors\n",
    "from TauGraphDataset import GetNeighborNodes, GetEdgeList, GetEdgeFeatureVectorsFromSourceNode, Graph2FlatZeropaddedList\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['text.usetex'] = True\n",
    "lw = 2\n",
    "xyLabelFontSize = 20\n",
    "xLabelPad = 10\n",
    "yLabelPad = 15\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetNames(datasetDir):\n",
    "    files = glob.glob(datasetDir + '/*.json', recursive=True)\n",
    "    files.sort()\n",
    "    datasetDirectories = [path.dirname(file) for file in files]\n",
    "    datasetnames = [path.normpath(dir).split(path.sep)[-1] for dir in datasetDirectories]\n",
    "    return datasetDirectories, datasetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n",
      "['Graphs_DYJetsToLL_M-50_genuineTaus_and_jets']\n"
     ]
    }
   ],
   "source": [
    "datasetDir = '/ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5_THESIS/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets'\n",
    "datasetDirs, datasetNames = getDatasetNames(datasetDir)\n",
    "print(datasetDirs)\n",
    "print(datasetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "<TauGraphDataset.TauGraphDataset object at 0x7fd184fbe668>\n"
     ]
    }
   ],
   "source": [
    "dataset = TauGraphDataset(datasetNames[0], datasetDirs[0])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Graphs_DYJetsToLL_M-50_genuineTaus_and_jets,\n",
      " directory: /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets\n",
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "label: 1\n",
      "graph classes: ['0', '1']\n",
      "dataset graph count: 200000\n",
      "nodeFeatKeys: ['pt', 'eta', 'phi', 'mass', 'charge', 'particleType', 'summand']\n",
      "edgeFeatKeys: ['deltaEta', 'deltaPhi', 'deltaR']\n",
      "graphFeatkeys: ['nodeCount']\n",
      "max node count: 81\n",
      "min node count: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'name: {datasetNames[0]},\\n directory: {datasetDirs[0]}')\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n",
    "print(f'label: {label}')\n",
    "print(f'graph classes: {dataset.graphClasses}')\n",
    "print(f'dataset graph count: {dataset.num_graphs}')\n",
    "print(f'nodeFeatKeys: {dataset.nodeFeatKeys}')\n",
    "print(f'edgeFeatKeys: {dataset.edgeFeatKeys}')\n",
    "print(f'graphFeatkeys: {dataset.graphFeatKeys}')\n",
    "print(f'max node count: {dataset.maxNodeCount}')\n",
    "print(f'min node count: {dataset.minNodeCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=25, num_edges=600,\n",
      "      ndata_schemes={'feat': Scheme(shape=(7,), dtype=torch.float64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)})\n",
      "nFeatDim: 7\n",
      "eFeatDim: 3\n",
      "maxNodeCount: 81\n",
      "\n",
      "node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\n",
      " nFeatDim + eFeatDim * (maxNodeCount-1) = 7 + 3 * 80 =  247\n",
      "The (maxNodeCount-1) comes from fully connected graphs without self-loops\n",
      "\n",
      "only node features dim per Node: nFeatDim=7\n",
      "\n",
      "node + edge features with zero padding to fill until maxNodeCount leads to inputsize: 20007\n",
      "check example: node + edge features list size: 20007\n",
      "\n",
      "only node features with zero padding to fill until maxNodeCount leads to inputsize: 567\n",
      "check example: only node features list size: 567\n"
     ]
    }
   ],
   "source": [
    "graphs, labels = dataset[:]\n",
    "g = graphs[0]\n",
    "nFeatDim = dataset.dim_nfeats\n",
    "eFeatDim = dataset.dim_efeats\n",
    "maxNodeCount = dataset.maxNodeCount\n",
    "print(g)\n",
    "print(f'nFeatDim: {nFeatDim}')\n",
    "print(f'eFeatDim: {eFeatDim}')\n",
    "print(f'maxNodeCount: {maxNodeCount}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDim = nFeatDim + eFeatDim * (maxNodeCount - 1)\n",
    "print(f'node + edge features dim per Node (includes zero padding if nodecount<maxnodecount):\\n',\n",
    "      f'nFeatDim + eFeatDim * (maxNodeCount-1) = {nFeatDim} + {eFeatDim} * {maxNodeCount - 1} = ',\n",
    "      f'{nodeAndEdgeFeaturePaddedDim}')\n",
    "print(f'The (maxNodeCount-1) comes from fully connected graphs without self-loops')\n",
    "print()\n",
    "print(f'only node features dim per Node: nFeatDim={nFeatDim}')\n",
    "print()\n",
    "\n",
    "nodeAndEdgeFeaturePaddedDimInputSize = nodeAndEdgeFeaturePaddedDim * maxNodeCount\n",
    "nodeFeaturePaddedDimInputSize = nFeatDim * maxNodeCount\n",
    "print(f'node + edge features with zero padding to fill until maxNodeCount leads to inputsize: {nodeAndEdgeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = True\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: node + edge features list size: {len(temp)}')\n",
    "print()\n",
    "print(f'only node features with zero padding to fill until maxNodeCount leads to inputsize: {nodeFeaturePaddedDimInputSize}')\n",
    "useEdgeFeat = False\n",
    "temp = np.array(Graph2FlatZeropaddedList(g, nFeatDim, eFeatDim, maxNodeCount, useEdgeFeat), dtype=np.float32)\n",
    "print(f'check example: only node features list size: {len(temp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputData(dgldataset, useEdgeFeatures):\n",
    "    inputs = [] \n",
    "    graphs, labels = dgldataset[:]\n",
    "    maxNodeCount = dgldataset.maxNodeCount\n",
    "    nFeatDim = dgldataset.dim_nfeats\n",
    "    eFeatDim = dgldataset.dim_efeats\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    it = 0\n",
    "    \n",
    "    for i in tqdm(range(len(graphs))):\n",
    "        inputs.append(Graph2FlatZeropaddedList(graphs[i], nFeatDim, eFeatDim, maxNodeCount, useEdgeFeatures))\n",
    "\n",
    "    # Stack all inputs_ vertically\n",
    "    print(type(inputs))\n",
    "    inputs = np.array(inputs, dtype=np.float32)\n",
    "    print(\"before vstack - Input shape: \", inputs.shape)\n",
    "    print(inputs)\n",
    "    print(type(inputs))\n",
    "    inputs = np.vstack(inputs)\n",
    "    print(inputs)\n",
    "    \n",
    "\n",
    "    # Stack all labels_ horizontally\n",
    "    labels = np.hstack(labels)\n",
    "\n",
    "    print(\"Input shape: \", inputs.shape)\n",
    "    print(\"Labels shape: \", labels.shape)\n",
    "\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    print(labels.shape)\n",
    "    print(labels[0])\n",
    "    end = time.time() - start\n",
    "    print(f'graphs to flattened zero padded list took {end:.2f} seconds ({end/60:.2f} minutes)')\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [15:59<00:00, 208.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "before vstack - Input shape:  (200000, 20007)\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.6791992   1.238197   -0.6319463  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 2.7011719  -0.5762505   2.2737963  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 4.2695312  -0.781518    0.42511293 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.66308594 -0.8608051   1.7206644  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.4853516   1.7232581  -3.10292    ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.8852539   1.0530717  -2.2728148  ...  0.          0.\n",
      "   0.        ]]\n",
      "Input shape:  (200000, 20007)\n",
      "Labels shape:  (200000,)\n",
      "(200000, 2)\n",
      "[0. 1.]\n",
      "graphs to flattened zero padded list took 988.91 seconds (16.48 minutes)\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = getInputData(dataset, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenerator(inputs, labels, batchsize):\n",
    "    while True:\n",
    "        start = 0\n",
    "        end = batchsize\n",
    "\n",
    "        while start  < len(inputs): \n",
    "            # load your images from numpy arrays or read from directory\n",
    "            x = inputs[start:end] \n",
    "            y = labels[start:end]\n",
    "            yield x, y\n",
    "\n",
    "            start += batchsize\n",
    "            end += batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"KerasModel_NodeAndEdgeFeat\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 32)                640256    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 652,850\n",
      "Trainable params: 652,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"KerasModel_NodeAndEdgeFeat\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 32)                640256    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 652,850\n",
      "Trainable params: 652,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "outputFolder = path.join(datasetDir, 'Output_Keras_NodeAndEdgeFeat')\n",
    "Path(outputFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = keras.Sequential(name=\"KerasModel_NodeAndEdgeFeat\")\n",
    "inputDim = (nFeatDim + eFeatDim * (maxNodeCount - 1)) * maxNodeCount\n",
    "model.add(keras.layers.InputLayer(input_shape=(inputDim,), name=\"input\"))\n",
    "model.add(keras.layers.Dense(32, activation='relu', name=\"dense1\"))\n",
    "model.add(keras.layers.Dense(16*16, activation='relu', name=\"dense2\"))\n",
    "model.add(keras.layers.Dense(16, activation='relu', name=\"dense3\"))\n",
    "model.add(keras.layers.Dense(2, activation='softmax', name=\"output\"))\n",
    "model.summary()\n",
    "\n",
    "lossfunction = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, min_delta=0.0005)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=path.join(outputFolder,'keras_nodeAndEdgeFeat_bestmodel.h5'), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "csvlogger = tf.keras.callbacks.CSVLogger(filename=path.join(outputFolder, 'results_keras_nodeAndEdgeFeat_bestmodel.csv'), separator=',', append=False)\n",
    "callbacks = [earlystopping, modelcheckpoint, csvlogger]\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss=lossfunction, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 160000\n",
      "validation samples: 30000\n",
      "test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_testAndVal, y_train, y_testAndVal = train_test_split(inputs, labels, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testAndVal, y_testAndVal, test_size=0.25, shuffle=False)\n",
    "print(f'train samples: {len(X_train)}')\n",
    "print(f'validation samples: {len(X_val)}')\n",
    "print(f'test samples: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "156/156 [==============================] - 36s 225ms/step - loss: 0.2755 - accuracy: 0.8914 - val_loss: 0.2423 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24234, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 2/100000\n",
      "156/156 [==============================] - 35s 223ms/step - loss: 0.2435 - accuracy: 0.9050 - val_loss: 0.2356 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24234 to 0.23562, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 3/100000\n",
      "156/156 [==============================] - 35s 223ms/step - loss: 0.2380 - accuracy: 0.9067 - val_loss: 0.2327 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.23562 to 0.23269, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 4/100000\n",
      "156/156 [==============================] - 34s 219ms/step - loss: 0.2342 - accuracy: 0.9079 - val_loss: 0.2304 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23269 to 0.23040, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 5/100000\n",
      "156/156 [==============================] - 35s 224ms/step - loss: 0.2302 - accuracy: 0.9094 - val_loss: 0.2281 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23040 to 0.22813, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 6/100000\n",
      "156/156 [==============================] - 34s 220ms/step - loss: 0.2262 - accuracy: 0.9108 - val_loss: 0.2260 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22813 to 0.22603, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 7/100000\n",
      "156/156 [==============================] - 33s 215ms/step - loss: 0.2226 - accuracy: 0.9120 - val_loss: 0.2255 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.22603 to 0.22549, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 8/100000\n",
      "156/156 [==============================] - 34s 219ms/step - loss: 0.2193 - accuracy: 0.9132 - val_loss: 0.2251 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.22549 to 0.22509, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 9/100000\n",
      "156/156 [==============================] - 34s 220ms/step - loss: 0.2167 - accuracy: 0.9145 - val_loss: 0.2246 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22509 to 0.22460, saving model to /ceph/aissac/ntuple_for_graphs/prod_2018_v2_processed_v5/trimmed_200000_and_cut_puppiWeightNoLep_greater_0_and_deltaR_smaller_0point5/Graphs_DYJetsToLL_M-50_genuineTaus_and_jets/Output_Keras_NodeAndEdgeFeat/keras_nodeAndEdgeFeat_bestmodel.h5\n",
      "Epoch 10/100000\n",
      "156/156 [==============================] - 34s 220ms/step - loss: 0.2141 - accuracy: 0.9155 - val_loss: 0.2254 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22460\n",
      "Epoch 11/100000\n",
      "156/156 [==============================] - 34s 221ms/step - loss: 0.2117 - accuracy: 0.9167 - val_loss: 0.2263 - val_accuracy: 0.9116\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22460\n",
      "Epoch 12/100000\n",
      "156/156 [==============================] - 35s 226ms/step - loss: 0.2095 - accuracy: 0.9176 - val_loss: 0.2309 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.22460\n",
      "Epoch 13/100000\n",
      "156/156 [==============================] - 35s 225ms/step - loss: 0.2078 - accuracy: 0.9185 - val_loss: 0.2314 - val_accuracy: 0.9098\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.22460\n",
      "Epoch 14/100000\n",
      "156/156 [==============================] - 35s 223ms/step - loss: 0.2059 - accuracy: 0.9190 - val_loss: 0.2307 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.22460\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "batchsize=1024\n",
    "history = model.fit(\n",
    "    x = datagenerator(X_train, y_train, batchsize=batchsize),\n",
    "    validation_data = datagenerator(X_val, y_val,batchsize=batchsize),\n",
    "    steps_per_epoch = len(X_train)//batchsize,\n",
    "    validation_steps = len(X_val)//batchsize,\n",
    "    shuffle=False, # at creation from rootfiles -> graphs already shuffled dataset\n",
    "    epochs = 100000, # doesnt matter, since we use early stopping\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "{'loss': [0.27547165751457214, 0.24352659285068512, 0.2380427122116089, 0.2341640740633011, 0.23015347123146057, 0.22622060775756836, 0.22260162234306335, 0.21933425962924957, 0.21669846773147583, 0.21408791840076447, 0.2116928994655609, 0.209464892745018, 0.20777589082717896, 0.20585913956165314], 'accuracy': [0.8914012312889099, 0.904998242855072, 0.9067343473434448, 0.90794837474823, 0.9094077348709106, 0.9107726812362671, 0.9119804501533508, 0.913213312625885, 0.9144588112831116, 0.9155155420303345, 0.9166918396949768, 0.917610228061676, 0.9185348749160767, 0.9189625978469849], 'val_loss': [0.24233965575695038, 0.23561985790729523, 0.232693612575531, 0.23039519786834717, 0.2281286120414734, 0.22602815926074982, 0.22549237310886383, 0.22509106993675232, 0.22459740936756134, 0.22544552385807037, 0.22630535066127777, 0.2308882176876068, 0.23137131333351135, 0.2307153195142746], 'val_accuracy': [0.9061826467514038, 0.9094154238700867, 0.9102572798728943, 0.9112338423728943, 0.9108297228813171, 0.911503255367279, 0.911772608757019, 0.9122440814971924, 0.912479817867279, 0.9125471711158752, 0.9115706086158752, 0.9100215435028076, 0.9097521305084229, 0.9103919863700867]}\n",
      "5000/5000 [==============================] - 26s 5ms/step - loss: 0.2037 - accuracy: 0.9191\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.9088\n",
      "Train: 0.919, Test: 0.909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NN output plot\n",
    "predictions = model.predict(X_test)\n",
    "print(type(predictions))\n",
    "#print(predictions)\n",
    "\n",
    "# TODO: check which order is actually signal (genuineTau) and which are background (fakeTau)\n",
    "genuineTau_decisions = predictions[:,0]\n",
    "fakeTau_decisions = predictions[:,1]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.hist(genuineTau_decisions, label='Genuine Taus', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, # normalize to form a probability density\n",
    "        linewidth=lw)\n",
    "plt.hist(fakeTau_decisions, label='Jets', \n",
    "        histtype='step', # lineplot that's unfilled\n",
    "        density=True, linewidth=lw) # normalize to form a probability density\n",
    "plt.xlabel('Neural Network output') # add x-axis label\n",
    "plt.ylabel('Arbitrary units') # add y-axis label\n",
    "plt.legend(loc=\"upper center\") # add legend\n",
    "plt.savefig(path.join(outputFolder, \"NN_output.png\"))\n",
    "plt.clf()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# most tutorials slice the prediction for whatever reason with [:,1] but why?\n",
    "# predictions_ = predictions[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test.argmax(axis=1), predictions[:, 1])\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "roc_auc = auc(fpr, tpr) # area under curve (AUC), ROC = Receiver operating characteristic\n",
    "plt.plot(fpr, tpr, label='ROC (area = %0.2f)'%(roc_auc), linewidth=lw) # plot test ROC curve\n",
    "plt.plot([0, 1], # x from 0 to 1\n",
    "         [0, 1], # y from 0 to 1\n",
    "         '--', # dashed line\n",
    "         color='red', label='Luck', linewidth=lw)\n",
    "\n",
    "plt.xlabel('False Positive Rate') # x-axis label\n",
    "plt.ylabel('True Positive Rate') # y-axis label\n",
    "plt.title('Receiver operating characteristic (ROC) curve') # title\n",
    "plt.legend() # add legend\n",
    "plt.grid() # add grid\n",
    "plt.savefig(path.join(outputFolder, \"ROC_Curve.png\"))\n",
    "plt.clf()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(history.history)\n",
    "\n",
    "# Plot accuracy of NN\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='best')\n",
    "plt.savefig(path.join(outputFolder, \"model_accuracy.png\"))\n",
    "plt.clf()\n",
    "# Plot loss of NN\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='best')\n",
    "plt.savefig(path.join(outputFolder, \"model_loss.png\"))\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e711687f31016629c64c84d23d27d9292aefc640ef90f9639fb07f22fea1b3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
